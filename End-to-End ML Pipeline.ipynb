{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORc8l7Vq+owvjaaMB0rPHR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E4W_UvMg1nRO","executionInfo":{"status":"ok","timestamp":1770883113467,"user_tz":-330,"elapsed":166,"user":{"displayName":"Mrunal Arote","userId":"09053581446988412726"}},"outputId":"660f0892-4c1a-4425-8ab2-d2dd4382f093"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Shape: (569, 32)\n","Columns: ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n","Target Column Detected: diagnosis\n","Numerical: ['id', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n","Categorical: []\n","\n","MODEL PERFORMANCE\n","Accuracy : 0.9649122807017544\n","Precision: 0.9651849217638692\n","Recall   : 0.9649122807017544\n","F1 Score : 0.9647247085304307\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           B       0.96      0.99      0.97        72\n","           M       0.97      0.93      0.95        42\n","\n","    accuracy                           0.96       114\n","   macro avg       0.97      0.96      0.96       114\n","weighted avg       0.97      0.96      0.96       114\n","\n","\n","Pipeline saved as trained_pipeline.pkl\n"]}],"source":["# ==========================================\n","# END-TO-END ML PIPELINE (CUSTOM DATASET)\n","# ==========================================\n","\n","import pandas as pd\n","import numpy as np\n","import pickle\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","# ---------------------------\n","# 1. Load Dataset\n","# ---------------------------\n","df = pd.read_csv(\"/content/breast-cancer.csv\")\n","\n","print(\"Dataset Shape:\", df.shape)\n","print(\"Columns:\", df.columns.tolist())\n","\n","# ---------------------------\n","# 2. Detect Target Column\n","# ---------------------------\n","possible_targets = [\"target\",\"label\",\"diagnosis\",\"class\",\"output\"]\n","\n","target_col = None\n","for col in possible_targets:\n","    if col in df.columns:\n","        target_col = col\n","        break\n","\n","# if not found â†’ assume last column is target\n","if target_col is None:\n","    target_col = df.columns[-1]\n","\n","print(\"Target Column Detected:\", target_col)\n","\n","# ---------------------------\n","# 3. Split Features & Target\n","# ---------------------------\n","X = df.drop(columns=[target_col])\n","y = df[target_col]\n","\n","# ---------------------------\n","# 4. Detect Column Types\n","# ---------------------------\n","num_features = X.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n","cat_features = X.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n","\n","print(\"Numerical:\", num_features)\n","print(\"Categorical:\", cat_features)\n","\n","# ---------------------------\n","# 5. Preprocessing Pipelines\n","# ---------------------------\n","num_pipeline = Pipeline([\n","    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","cat_pipeline = Pipeline([\n","    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n","    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","preprocessor = ColumnTransformer([\n","    (\"num\", num_pipeline, num_features),\n","    (\"cat\", cat_pipeline, cat_features)\n","])\n","\n","# ---------------------------\n","# 6. Full Pipeline\n","# ---------------------------\n","pipeline = Pipeline([\n","    (\"preprocessing\", preprocessor),\n","    (\"model\", LogisticRegression(max_iter=1000))\n","])\n","\n","# ---------------------------\n","# 7. Train Test Split\n","# ---------------------------\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","# ---------------------------\n","# 8. Train Model\n","# ---------------------------\n","pipeline.fit(X_train, y_train)\n","\n","# ---------------------------\n","# 9. Predictions\n","# ---------------------------\n","y_pred = pipeline.predict(X_test)\n","\n","# ---------------------------\n","# 10. Evaluation\n","# ---------------------------\n","print(\"\\nMODEL PERFORMANCE\")\n","print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n","print(\"Precision:\", precision_score(y_test, y_pred, average=\"weighted\"))\n","print(\"Recall   :\", recall_score(y_test, y_pred, average=\"weighted\"))\n","print(\"F1 Score :\", f1_score(y_test, y_pred, average=\"weighted\"))\n","\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# ---------------------------\n","# 11. Save Model\n","# ---------------------------\n","with open(\"trained_pipeline.pkl\", \"wb\") as f:\n","    pickle.dump(pipeline, f)\n","\n","print(\"\\nPipeline saved as trained_pipeline.pkl\")"]}]}